# The point of this is to implement a typical neural net with 1 hidden layer and ReLU activation. 

import numpy as np

n = 5
X = np.array([-2, -1, 0, 1, 2])
y = np.array([1, -1, 1, 1, -1])
